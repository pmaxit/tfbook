{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeab5dfb",
   "metadata": {},
   "source": [
    "# Siamese model for name ambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f67131",
   "metadata": {},
   "source": [
    "Here, in this notebook, we will create a model that can tell the difference between \"Paul\" & \"Paula\". This model can be used as a drop in replacement to string comparison methods which can return score from 0 to 1 depending upon the similarity. For example, here is the intended use:\n",
    "\n",
    "> compare(\"Paul\", \"Paula\") -> 0.3  # It indicates different gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aee820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_names = pd.read_csv('../data/name_pairs.txt', sep=',', names=['name_a','name_b'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d32064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16048</th>\n",
       "      <td>Tine</td>\n",
       "      <td>Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8327</th>\n",
       "      <td>Kristin</td>\n",
       "      <td>Krissy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Ale</td>\n",
       "      <td>Alisha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>Clifton</td>\n",
       "      <td>Tone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>Foncho</td>\n",
       "      <td>Fon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13622</th>\n",
       "      <td>Radisa</td>\n",
       "      <td>Radomirm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>Chus</td>\n",
       "      <td>Suso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>Erma</td>\n",
       "      <td>Em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9708</th>\n",
       "      <td>Madzia</td>\n",
       "      <td>Magdzia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>Chema</td>\n",
       "      <td>Josemaria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name_a     name_b\n",
       "16048     Tine     Martin\n",
       "8327   Kristin     Krissy\n",
       "305        Ale     Alisha\n",
       "2914   Clifton       Tone\n",
       "4824    Foncho        Fon\n",
       "13622   Radisa   Radomirm\n",
       "2792      Chus       Suso\n",
       "4543      Erma         Em\n",
       "9708    Madzia    Magdzia\n",
       "2643     Chema  Josemaria"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_names.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def syllables(word):\n",
    "    # single syllable word\n",
    "    if len(re.findall('[aeiouy]', word)) <= 1:\n",
    "        return [word]\n",
    "\n",
    "    # sonority hierarchy: vowels, nasals, fricatives, stops\n",
    "    hierarchy = {\n",
    "        'a': 4, 'e': 4, 'i': 4, 'o': 4, 'u': 4, 'y': 4,\n",
    "        'l': 3, 'm': 3, 'n': 3, 'r': 3, 'w': 3,\n",
    "        'f': 2, 's': 2, 'v': 2, 'z': 2,\n",
    "        'b': 1, 'c': 1, 'd': 1, 'g': 1, 'h': 1, 'j': 1, 'k': 1, 'p': 1, 'q': 1, 't': 1, 'x': 1,\n",
    "    }\n",
    "    syllables_values = [(c, hierarchy[c]) for c in word]\n",
    "\n",
    "    syllables = []\n",
    "    syll = syllables_values[0][0]\n",
    "    for trigram in zip(*[syllables_values[i:] for i in range(3)]):\n",
    "        (phonemes, values) = zip(*trigram)\n",
    "        (previous, val, following) = values\n",
    "        phoneme = phonemes[1]\n",
    "\n",
    "        if previous > val < following:\n",
    "            syllables.append(syll)\n",
    "            syll = phoneme\n",
    "        elif previous >= val == following:\n",
    "            syll += phoneme\n",
    "            syllables.append(syll)\n",
    "            syll = ''\n",
    "        else:\n",
    "            syll += phoneme\n",
    "    syll += syllables_values[-1][0]\n",
    "    syllables.append(syll)\n",
    "\n",
    "    final_syllables = []\n",
    "    front = ''\n",
    "    for (i, syllable) in enumerate(syllables):\n",
    "        if not re.search('[aeiouy]', syllable):\n",
    "            if len(final_syllables) == 0:\n",
    "                front += syllable\n",
    "            else:\n",
    "                final_syllables = final_syllables[:-1] \\\n",
    "                                  + [final_syllables[-1] + syllable]\n",
    "        else:\n",
    "            if len(final_syllables) == 0:\n",
    "                final_syllables.append(front + syllable)\n",
    "            else:\n",
    "                final_syllables.append(syllable)\n",
    "    return final_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c398540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puneet/Envs/venv/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from abydos.distance import (IterativeSubString, BISIM, DiscountedLevenshtein, Prefix, LCSstr, MLIPNS, Strcmp95,\n",
    "MRA, Editex, SAPS, FlexMetric, JaroWinkler, HigueraMico, Sift4, Eudex, ALINE, Covington, PhoneticEditDistance)\n",
    "\n",
    "from abydos.phonetic import PSHPSoundexFirst, Ainsworth\n",
    "pshp_soundex_first = PSHPSoundexFirst()\n",
    "pe = Ainsworth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc26a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abydos.phones import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68006c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "iss = IterativeSubString()\n",
    "bisim = BISIM()\n",
    "dlev = DiscountedLevenshtein()\n",
    "prefix = Prefix()\n",
    "lcs = LCSstr()\n",
    "mlipns = MLIPNS()\n",
    "strcmp95 = Strcmp95()\n",
    "mra = MRA()\n",
    "editex = Editex()\n",
    "saps = SAPS()\n",
    "flexmetric = FlexMetric()\n",
    "jaro = JaroWinkler(mode='Jaro')\n",
    "higuera_mico = HigueraMico()\n",
    "sift4 = Sift4()\n",
    "eudex = Eudex()\n",
    "aline = ALINE()\n",
    "covington = Covington()\n",
    "phonetic_edit = PhoneticEditDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d47c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [iss, bisim, dlev, prefix, lcs, mlipns, strcmp95, mra, editex, saps, flexmetric, jaro, higuera_mico, sift4, eudex,\n",
    "         aline, covington, phonetic_edit]\n",
    "\n",
    "algo_names = ['iterativesubstring', 'bisim', 'discountedlevenshtein', 'prefix', 'lcsstr', 'mlipns', 'strcmp95', 'mra',\n",
    "              'editex', 'saps', 'flexmetric', 'jaro', 'higueramico', 'sift4', 'eudex', 'aline', 'covington',\n",
    "              'phoneticeditdistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ipa(name_a, name_b):\n",
    "    feat1 = ipa_to_features(pe.encode(name_a))\n",
    "    feat2 = ipa_to_features(pe.encode(name_b))\n",
    "    score = sum(cmp_features(f1, f2) for f1, f2 in zip(feat1, feat2))/len(feat1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def featurize(df):\n",
    "    if len(df.columns)==3:\n",
    "        df.columns=['a', 'b', 'target']\n",
    "    elif len(df.columns)==2:\n",
    "        df.columns=['a', 'b']\n",
    "    else:\n",
    "        df = df.rename(columns={df.columns[0]: 'a', df.columns[1]: 'b' })\n",
    "        \n",
    "    df['name_a'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['a']).lower().strip()), axis=1)\n",
    "    df['name_b'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['b']).lower().strip()), axis=1)\n",
    "    \n",
    "    df['syll_a'] = df.apply(lambda row: syllables(row.name_a), axis=1)\n",
    "    df['syll_b'] = df.apply(lambda row: syllables(row.name_b), axis=1)\n",
    "    \n",
    "    df['partial'] = df.apply(lambda row: fuzz.partial_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    df['tkn_sort'] = df.apply(lambda row: fuzz.token_sort_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    df['tkn_set'] = df.apply(lambda row: fuzz.token_set_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    \n",
    "    df['sum_ipa'] = df.apply(lambda row: sum_ipa(row.name_a, row.name_b), axis=1)\n",
    "    \n",
    "    df['pshp_soundex_first'] = df.apply(\n",
    "        lambda row: 1 if pshp_soundex_first.encode(row.name_a)==pshp_soundex_first.encode(row.name_b) else 0, axis=1)\n",
    "    \n",
    "    for i, algo in enumerate(algos):\n",
    "            df[algo_names[i]] = df.apply(lambda row: algo.sim(row.name_a, row.name_b), axis=1)\n",
    "            \n",
    "    df.drop(['syll_a', 'syll_b'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8fb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Class\n",
    "alt_names['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccddfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(30)\n",
    "\n",
    "# Use combinatorics to generate negative class\n",
    "all_names = alt_names.loc[:, 'name_a':'name_b'].values.tolist()\n",
    "unique_names = list(set([item for items in all_names for item in items]))\n",
    "alt_pairs = list(zip(alt_names.name_a, alt_names.name_b))+ list(zip(alt_names.name_b, alt_names.name_a))\n",
    "comb = list(combinations(unique_names, 2))\n",
    "non_alt = list(set(comb) - set(alt_pairs))\n",
    "# Undersample the negative class for 1:4 class imbalance instead of 1:1000 extreme class imbalance\n",
    "non_alt = pd.DataFrame(random.choices(non_alt, k=70040), columns=['name_a', 'name_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive class ratio 1:4\n"
     ]
    }
   ],
   "source": [
    "print('positive class ratio 1:{}'.format(int(len(non_alt)/len(alt_names))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f022888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Class\n",
    "non_alt['target'] = 0\n",
    "df = pd.concat([alt_names, non_alt])\n",
    "non_alt = None\n",
    "alt_names = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c59053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = featurize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904bc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>...</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>covington</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51948</th>\n",
       "      <td>Shah</td>\n",
       "      <td>Tashe</td>\n",
       "      <td>0</td>\n",
       "      <td>shah</td>\n",
       "      <td>tashe</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.587097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15602</th>\n",
       "      <td>Aravindha</td>\n",
       "      <td>Kim</td>\n",
       "      <td>0</td>\n",
       "      <td>aravindha</td>\n",
       "      <td>kim</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.261649</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.187234</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.288530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>Bart</td>\n",
       "      <td>Almina</td>\n",
       "      <td>0</td>\n",
       "      <td>bart</td>\n",
       "      <td>almina</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.846078</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.540323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>Tadzio</td>\n",
       "      <td>Cecalie</td>\n",
       "      <td>0</td>\n",
       "      <td>tadzio</td>\n",
       "      <td>cecalie</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.760753</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.922549</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.755760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Kate</td>\n",
       "      <td>1</td>\n",
       "      <td>cat</td>\n",
       "      <td>kate</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.868627</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               a        b  target     name_a   name_b  partial  tkn_sort  \\\n",
       "51948       Shah    Tashe       0       shah    tashe       53        20   \n",
       "15602  Aravindha      Kim       0  aravindha      kim       43        13   \n",
       "4102        Bart   Almina       0       bart   almina       50        17   \n",
       "1384      Tadzio  Cecalie       0     tadzio  cecalie       67        12   \n",
       "2417         Cat     Kate       1        cat     kate       57        50   \n",
       "\n",
       "       tkn_set   sum_ipa  pshp_soundex_first  ...    editex  saps  flexmetric  \\\n",
       "51948       20  0.838710                   0  ...  0.300000   0.0    0.460000   \n",
       "15602       13  0.261649                   0  ...  0.222222   0.0    0.255556   \n",
       "4102        17  0.655914                   0  ...  0.083333   0.0    0.116667   \n",
       "1384        12  0.760753                   0  ...  0.285714   0.0    0.528571   \n",
       "2417        50  1.000000                   1  ...  0.625000   0.0    0.850000   \n",
       "\n",
       "           jaro  higueramico     sift4     eudex     aline  covington  \\\n",
       "51948  0.633333     0.300000  0.400000  0.933824  0.592593   0.622222   \n",
       "15602  0.481481     0.000000  0.111111  0.745098  0.187234   0.300000   \n",
       "4102   0.472222     0.061905  0.166667  0.846078  0.246667   0.377551   \n",
       "1384   0.539683     0.232143  0.285714  0.922549  0.515152   0.546154   \n",
       "2417   0.722222     0.500000  0.500000  0.868627  0.700000   0.671429   \n",
       "\n",
       "       phoneticeditdistance  \n",
       "51948              0.587097  \n",
       "15602              0.288530  \n",
       "4102               0.540323  \n",
       "1384               0.755760  \n",
       "2417               0.741935  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2358187/1973277800.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X = df.drop('target',1)\n"
     ]
    }
   ],
   "source": [
    "y = df.target\n",
    "X = df.drop('target',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd0344",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_1 = make_pipeline(\n",
    "    MaxAbsScaler(),\n",
    "    MinMaxScaler(),\n",
    "    RandomForestClassifier(\n",
    "                bootstrap=False,\n",
    "            criterion=\"gini\",\n",
    "            max_features=0.25,\n",
    "            min_samples_leaf=1,\n",
    "            min_samples_split=4,\n",
    "            n_estimators=100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01495c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2358187/1107818783.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  base_model_1.fit(X_train.drop(['a', 'b', 'name_a', 'name_b'], 1), y_train)\n",
      "/tmp/ipykernel_2358187/1107818783.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  oof_pred['predict_proba'] = base_model_1.predict_proba(X_test.drop(['a', 'b', 'name_a', 'name_b'], 1))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predict_proba'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3745\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3746\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3747\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predict_proba'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2358187/1107818783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbase_model_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name_a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name_b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moof_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name_a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name_b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moof_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3605\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3606\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3790\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexisting_piece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     def _set_value(\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3747\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3751\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iset_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_block_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, klass)\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_pandas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1922\u001b[0;31m     \u001b[0mcheck_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/venv/lib/python3.9/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcheck_ndim\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             )\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1965\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m                 \u001b[0;34mf\"placement implies {len(placement)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "fold = 1\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(stratified_kfold.split(X,y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    oof_pred = X_test[['name_a', 'name_b']]\n",
    "    base_model_1.fit(X_train.drop(['a', 'b', 'name_a', 'name_b'], 1), y_train)\n",
    "    \n",
    "    oof_pred['predict_proba'] = base_model_1.predict_proba(X_test.drop(['a', 'b', 'name_a', 'name_b'], 1))\n",
    "    \n",
    "    oof_pred['target'] = y_test.tolist()\n",
    "    \n",
    "    print('completed fold {} of 10'.format(fold))\n",
    "    scores.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d32b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
