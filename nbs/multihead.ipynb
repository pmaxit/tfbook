{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Sentiment Analysis\n",
    "\n",
    "For this article, we'll use IMDB dataset that contains 50,000 movie reviews from Internet movie database. The IMDB dataset usually comes pre-packaged with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 09:44:12.262673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 09:44:12.263254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 09:44:12.268697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 09:44:12.269368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 09:44:12.269952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 09:44:12.270500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], enable=True)\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000\n",
    "seed = 42 \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size, seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged Tensors\n",
    "\n",
    "Ragged Tensors are new first class citizens in Tensorflow library. This allows us to work with non-similar tensor lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train_x = tf.ragged.constant(x_train)\n",
    "r_test_x  = tf.ragged.constant(x_test)\n",
    "\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices((r_train_x, y_train))\n",
    "raw_test_ds = tf.data.Dataset.from_tensor_slices((r_test_x, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds_str =            raw_train_ds \\\n",
    "                        .cache() \\\n",
    "                        .shuffle(buffer_size=BUFFER_SIZE) \\\n",
    "                        .batch(batch_size=BATCH_SIZE, drop_remainder=True) \\\n",
    "                        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                       \n",
    "                        \n",
    "test_ds_str =            raw_test_ds \\\n",
    "                        .cache() \\\n",
    "                        .shuffle(buffer_size=BUFFER_SIZE) \\\n",
    "                        .batch(batch_size=BATCH_SIZE, drop_remainder=True) \\\n",
    "                        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                       \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras import Input, Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 64)          640000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,089\n",
      "Trainable params: 673,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(None, ), ragged=True)\n",
    "x = Embedding(vocab_size, 64)(input1)\n",
    "x = LSTM(64)(x)\n",
    "\n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=[out])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='bce', metrics=['acc'])\n",
    "\n",
    "filepath = 'model.h5'\n",
    "\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(filepath, verbose=0, save_weights_only=True, \n",
    "                                        monitor='val_loss', mode='auto', save_best_only=True)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(train_ds_str, epochs=100, batch_size=16, \n",
    "                    validation_data= test_ds_str, callbacks=[mc, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
